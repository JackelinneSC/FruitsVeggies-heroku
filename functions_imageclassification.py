# -*- coding: utf-8 -*-
"""Functions_ImageClassification.ipynb

Automatically generated by Colaboratory.

The original file is located at
    https://colab.research.google.com/drive/1H9KABBPiTHftKdQglIDlRDN6HDwPWJRV
"""
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import pandas as pd
from mtranslate import translate

# Define image size
IMG_SIZE = 224
# Define batch size
BATCH_SIZE = 32
# Load unique labels
unique_labels = pd.read_csv("labels.csv", header=None)
unique_labels = unique_labels.to_numpy()


# Function to preprocess an image
def process_image(image_path):
    """
  Turns the image into a Tensor.
  :param str image_path: image file path
  """
    # Read in an image file
    image = tf.io.read_file(image_path)
    # Turn the jpeg image into numerical Tensor with 3 color channels
    image = tf.image.decode_jpeg(image, channels=3)
    # Convert the color channel values from 0-255 to 0-1 values
    image = tf.image.convert_image_dtype(image, tf.float32)
    # Resize the image to our desired value (224,224)
    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])

    return image


# Function that returns a tuple (image,tuple)
def get_image_label_tuple(image_path, label):
    """
  Takes an image file path name an the associated label. Then, it processes the image to convert it into Tensor. 
  Finally returns the tuple (image,label).
  """
    image = process_image(image_path)
    return image, label


# Function to turn our data into batches
def data_to_batch(X, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):
    """
  Creates a batch of data out of an image (X) and label (y) pairs.
  If it's training data, then it shuffles it.
  If it's validation data, then it does not shuffle it.
  If it's test data, it must not have a label.
  """

    # if the data is the test set, there is no labels
    if test_data:
        print("Creating test data batches")
        data = tf.data.Dataset.from_tensor_slices(tf.constant(X))
        data_batch = data.map(process_image).batch(BATCH_SIZE)
        return data_batch

    # if ihe data is the valid set, the data is not shuffled
    elif valid_data:
        print("creating valid data batches")
        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),  # filepaths
                                                   tf.constant(y)))  # labels
        data_batch = data.map(get_image_label_tuple).batch(BATCH_SIZE)  # creates the tuple with the image preprocessed
        return data_batch

    else:
        # It is training data
        print("Creating training data batches")
        data = tf.data.Dataset.from_tensor_slices((tf.constant(X),  # filepaths
                                                   tf.constant(y)))  # labels

        # Shuffle filepaths and lables before mapping function 'process_image()'
        data = data.shuffle(buffer_size=len(X))
        data = data.map(get_image_label_tuple)
        data_batch = data.batch(BATCH_SIZE)
        return data_batch


# Function to load model
def load_model(model_path):
    """
  Loads a saved model from a specific path.
  """
    print(f"Loading saved model from: {model_path}")
    model = tf.keras.models.load_model(model_path,
                                       custom_objects={"KerasLayer": hub.KerasLayer})
    return model


# Load model trained with full dataset.
load_full_model = load_model("model/20220317-18301647541833-full-imagesv3-mobilenetv2-Adam.h5")


# Turn prediction probabilities into their respective label.
def get_predicted_label(prediction_probabilities):
    """
  Turns an array of prediction probabilities into a label.
  """
    print("Unique labels")
    for a in unique_labels:
        print(a)
    print("End")
    return unique_labels[np.argmax(prediction_probabilities)]


# Create a function to unbatch a batch dataset with labels
def unbatchify(batch_data, has_labels=True):
    """
  Takes a batched dataset of (image, label) Tensors. It returns separate arrays of images and labels.
  """
    images = []
    labels = []

    if has_labels:
        # Loop through unbatched data
        for image, label in batch_data.unbatch().as_numpy_iterator():
            images.append(image)
            labels.append(unique_labels[np.argmax(label)])
        return images, labels
    else:
        for image in batch_data.unbatch().as_numpy_iterator():
            images.append(image)

    print("The unbatchify process has finished. The result are probabilities: ")
    return images


# Predict label of the custom images uploaded by the user
def predict_custom_image(custom_data):
    """
  Predicts the label of an image. 
  Parameter: location of the image.
  """

    # Predict label
    custom_pred = load_full_model.predict(custom_data)
    # Get custom image prediction labels
    custom_pred_labels = [get_predicted_label(custom_pred[i]) for i in range(len(custom_pred))]
    return custom_pred_labels


# Function to translate images uploaded by the user
def translate_images(custom_images, predicted_labels):
    spanish_labels = []
    for j in range(0, len(custom_images)):
        spanish_labels.append(translate(str(predicted_labels[j]), "es", "en"))
    print(f'Spanish labels: {spanish_labels}')
    return spanish_labels
